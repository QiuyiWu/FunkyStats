r.coef = coef1 - coef2
mse = t(r.coef) %*% inprod.mat %*% (r.coef)
return(sqrt(mse[1,1]))
}
test.smooth <- smooth.basis(t.vec, y = y.obs, fdPar(x.basis,lambda = 1))
test.smooth2 <- smooth.basis(t.vec, y = y.obs, fdPar(x.basis,lambda = .99))
all.equal(get_coefs(X,y.obs,1,pen.mat),test.smooth$fd$coefs)
RMSE(test.smooth$fd$coefs,test.smooth2$fd$coefs, inprod.mat)
# Chunk 5
l.vec <- exp(seq(1,6,.2))
output <- matrix(NA,40,8)
output.objects <- list()
for(ii in 1:nrow(output)){
noise <- rnorm(length(y.true),0,noise.sd)
y.obs <- y.true + noise
# Do a grid search to find the optimal smoothing parameters using the
# different procedures
unweighted.press.vec <- rep(NA,length(l.vec))
unweighted.gcv.vec <- rep(NA,length(l.vec))
weighted.press.vec <- rep(NA,length(l.vec))
weighted.gcv.vec <- rep(NA,length(l.vec))
for(jj in 1:length(l.vec)){
unweighted.press.vec[jj] <- get_naive_press(X = X, y = y.obs,lambda = l.vec[jj],
pen.mat = pen.mat)
unweighted.gcv.vec[jj] <- get_naive_gcv(X = X, y = y.obs,lambda = l.vec[jj],
pen.mat = pen.mat)
weighted.press.vec[jj] <- get_naive_press(X = X, y = y.obs,lambda = l.vec[jj],
pen.mat = pen.mat.W, W = W)
weighted.gcv.vec[jj] <- get_naive_gcv(X = X, y = y.obs,lambda = l.vec[jj],
pen.mat = pen.mat.W, W = W)
}
up.i = which.min(unweighted.press.vec)
ug.i = which.min(unweighted.gcv.vec)
wp.i = which.min(weighted.press.vec)
wg.i = which.min(weighted.gcv.vec)
up.l = l.vec[up.i]
ug.l = l.vec[ug.i]
wp.l = l.vec[wp.i]
wg.l = l.vec[wg.i]
# Coefs give smooth in original space
up.coefs = get_coefs(X,y.obs,up.l,pen.mat)
ug.coefs = get_coefs(X,y.obs,ug.l,pen.mat)
# Coefs give smooth in transformed space
# i.e., W %*% X %*% wp.coefs gives weighted-PRESS-optimal smooth
# in transformed space
wp.coefs = get_coefs(X,y.obs,wp.l,pen.mat,W)
wg.coefs = get_coefs(X,y.obs,wg.l,pen.mat,W)
# W %*% X %*% wp.coefs gives you the smoothed predictions in transformed space
# To transform back, multiply by W^{-1}
# The predictions back in the original space are
# W^{-1} %*% W %*% X %*% wp.coefs = X %*% wp.coefs
# Because both the weighted and unweighted coefs are multiplied by (the
# original) X, I can use the RMSE function defined above without adjustment.
up.rmse = RMSE(up.coefs,true.coefs,inprod.mat)
ug.rmse = RMSE(ug.coefs,true.coefs,inprod.mat)
wp.rmse = RMSE(wp.coefs,true.coefs,inprod.mat)
wg.rmse = RMSE(wg.coefs,true.coefs,inprod.mat)
output[ii,] = c(up.l,ug.l,wp.l,wg.l,up.rmse,ug.rmse,wp.rmse,wg.rmse)
output.objects[[ii]] = list(noise,y.obs,
unweighted.press.vec,
unweighted.gcv.vec,
weighted.press.vec,
weighted.gcv.vec,
up.coefs,ug.coefs,wp.coefs,wg.coefs)
}
colnames(output) <- c("up.l","ug.l","wp.l","wg.l","up.rmse","ug.rmse","wp.rmse","wg.rmse")
output <- round(output,3) %>% as.data.frame() %>%
mutate(ID=row_number(),.before = 1,
p.improved = (wp.rmse<up.rmse),
g.improved =(wg.rmse<ug.rmse))
output
mean(output$g.improved)
l.vec <- exp(seq(1,6,.2))
output <- matrix(NA,20,8)
output.objects <- list()
for(ii in 1:nrow(output)){
noise <- rnorm(length(y.true),0,noise.sd)
y.obs <- y.true + noise
# Do a grid search to find the optimal smoothing parameters using the
# different procedures
unweighted.press.vec <- rep(NA,length(l.vec))
unweighted.gcv.vec <- rep(NA,length(l.vec))
weighted.press.vec <- rep(NA,length(l.vec))
weighted.gcv.vec <- rep(NA,length(l.vec))
for(jj in 1:length(l.vec)){
unweighted.press.vec[jj] <- get_naive_press(X = X, y = y.obs,lambda = l.vec[jj],
pen.mat = pen.mat)
unweighted.gcv.vec[jj] <- get_naive_gcv(X = X, y = y.obs,lambda = l.vec[jj],
pen.mat = pen.mat)
weighted.press.vec[jj] <- get_naive_press(X = X, y = y.obs,lambda = l.vec[jj],
pen.mat = pen.mat.W, W = W)
weighted.gcv.vec[jj] <- get_naive_gcv(X = X, y = y.obs,lambda = l.vec[jj],
pen.mat = pen.mat.W, W = W)
}
up.i = which.min(unweighted.press.vec)
ug.i = which.min(unweighted.gcv.vec)
wp.i = which.min(weighted.press.vec)
wg.i = which.min(weighted.gcv.vec)
up.l = l.vec[up.i]
ug.l = l.vec[ug.i]
wp.l = l.vec[wp.i]
wg.l = l.vec[wg.i]
# Coefs give smooth in original space
up.coefs = get_coefs(X,y.obs,up.l,pen.mat)
ug.coefs = get_coefs(X,y.obs,ug.l,pen.mat)
# Coefs give smooth in transformed space
# i.e., W %*% X %*% wp.coefs gives weighted-PRESS-optimal smooth
# in transformed space
wp.coefs = get_coefs(X,y.obs,wp.l,pen.mat.W,W)
wg.coefs = get_coefs(X,y.obs,wg.l,pen.mat.W,W)
# W %*% X %*% wp.coefs gives you the smoothed predictions in transformed space
# To transform back, multiply by W^{-1}
# The predictions back in the original space are
# W^{-1} %*% W %*% X %*% wp.coefs = X %*% wp.coefs
# Because both the weighted and unweighted coefs are multiplied by (the
# original) X, I can use the RMSE function defined above without adjustment.
up.rmse = RMSE(up.coefs,true.coefs,inprod.mat)
ug.rmse = RMSE(ug.coefs,true.coefs,inprod.mat)
wp.rmse = RMSE(wp.coefs,true.coefs,inprod.mat)
wg.rmse = RMSE(wg.coefs,true.coefs,inprod.mat)
output[ii,] = c(up.l,ug.l,wp.l,wg.l,up.rmse,ug.rmse,wp.rmse,wg.rmse)
output.objects[[ii]] = list(noise,y.obs,
unweighted.press.vec,
unweighted.gcv.vec,
weighted.press.vec,
weighted.gcv.vec,
up.coefs,ug.coefs,wp.coefs,wg.coefs)
}
colnames(output) <- c("up.l","ug.l","wp.l","wg.l","up.rmse","ug.rmse","wp.rmse","wg.rmse")
output <- round(output,3) %>% as.data.frame() %>%
mutate(ID=row_number(),.before = 1,
p.improved = (wp.rmse<up.rmse),
g.improved =(wg.rmse<ug.rmse))
output
mean(output$g.improved)
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE,warning=F,message=F)
library(tidyverse)
# Chunk 2
set.seed(11235)
library(fda)
t.vec = seq(.1,9.9,.1)
x.basis <- create.bspline.basis(range(t.vec),nbasis = round(.8*length(t.vec)))
inprod.mat <- inprod(x.basis,x.basis)
X <- eval.basis(t.vec, x.basis)
pen.mat <- getbasispenalty(x.basis,2)
y.true <- 2*t.vec - .1*t.vec^2
noise.sd <- .25*(2 + (1:length(y.true)/20))
y.obs = y.true+rnorm(length(y.true),0,noise.sd)
W = diag(1/noise.sd)
W.fd <- smooth.basis(t.vec,diag(W),x.basis)
pen.mat.W <- inprod(x.basis,x.basis,2,2,wtfd = W.fd$fd * W.fd$fd)
plot(t.vec,y.obs)
points(t.vec,y.true,col="green")
# Chunk 4
tr <- function(X) sum(diag(X))
get_hat <- function(X,w=NULL,lambda=0,pen.mat = diag(1,ncol(X))){
X = as.matrix(X)
if(is.null(w)){
z = X
}
else{
z = w %*% X
}
H = z %*% solve(t(z) %*% z + lambda*pen.mat) %*% t(z)
return(H)
}
get_naive_press <- function(X,y,W=NULL,lambda=0,pen.mat = F){
n = length(y)
output.vec = rep(0,n)
X = as.matrix(X)
if(is.null(W)==F){
X = W %*% X
y = W %*% y
}
for(ii in 1:n){
z = X[-ii,] %>% as.matrix()
temp.y = y[-ii] %>% as.matrix()
temp.beta = solve(t(z) %*% z + lambda*pen.mat) %*% t(z) %*% temp.y
pred = t(as.matrix(X[ii,])) %*% temp.beta
output.vec[ii] = (pred - y[ii])^2
}
return((1/n) * sum(output.vec))
}
get_naive_gcv <- function(X,y,W=NULL,lambda=0,pen.mat = diag(1,ncol(X))){
A = get_hat(X,W,lambda,pen.mat)
n = length(y)
output.vec = rep(0,n)
X = as.matrix(X)
if(is.null(W)==F){
X = W %*% X
y = W %*% y
}
for(ii in 1:n){
z = X[-ii,] %>% as.matrix()
temp.y = y[-ii] %>% as.matrix()
temp.beta = solve(t(z) %*% z + lambda*pen.mat) %*% t(z) %*% temp.y
pred = t(as.matrix(X[ii,])) %*% temp.beta
gcv.w_i = (1-A[ii,ii])/(1-(1/n)*tr(A))
output.vec[ii] = (pred - y[ii])^2 * gcv.w_i
}
return((1/n) * sum(output.vec))
}
get_coefs <- function(X,y, lambda,pen.mat, W = NULL){
# If a W is given, COEFS WILL BE FOR THE SMOOTH IN THE TRANSFORMED SPACE
n = nrow(X)
y = as.matrix(y,length(y),1)
if(is.null(W)==F){
X = W %*% X
y = W %*% y
}
output = solve(t(X) %*% X + pen.mat*lambda) %*% t(X) %*% y
return(output)
}
true.coefs <- get_coefs(X, y.true,0,pen.mat)
inprod.mat <- inprod(x.basis, x.basis)
RMSE <- function(coef1,coef2, inprod.mat = inprod.mat){
r.coef = coef1 - coef2
mse = t(r.coef) %*% inprod.mat %*% (r.coef)
return(sqrt(mse[1,1]))
}
test.smooth <- smooth.basis(t.vec, y = y.obs, fdPar(x.basis,lambda = 1))
test.smooth2 <- smooth.basis(t.vec, y = y.obs, fdPar(x.basis,lambda = .99))
all.equal(get_coefs(X,y.obs,1,pen.mat),test.smooth$fd$coefs)
RMSE(test.smooth$fd$coefs,test.smooth2$fd$coefs, inprod.mat)
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE,warning=F,message=F)
library(tidyverse)
# Chunk 2
set.seed(11235)
library(fda)
t.vec = seq(.1,9.9,.1)
x.basis <- create.bspline.basis(range(t.vec),nbasis = round(.8*length(t.vec)))
inprod.mat <- inprod(x.basis,x.basis)
X <- eval.basis(t.vec, x.basis)
pen.mat <- getbasispenalty(x.basis,2)
y.true <- 2*t.vec - .1*t.vec^2
noise.sd <- .25*(2 + (1:length(y.true)/20))
y.obs = y.true+rnorm(length(y.true),0,noise.sd)
W = diag(1/noise.sd)
W.fd <- smooth.basis(t.vec,diag(W),x.basis)
pen.mat.W <- inprod(x.basis,x.basis,2,2,wtfd = W.fd$fd * W.fd$fd)
plot(t.vec,y.obs)
points(t.vec,y.true,col="green")
# Chunk 4
tr <- function(X) sum(diag(X))
get_hat <- function(X,w=NULL,lambda=0,pen.mat = diag(1,ncol(X))){
X = as.matrix(X)
if(is.null(w)){
z = X
}
else{
z = w %*% X
}
H = z %*% solve(t(z) %*% z + lambda*pen.mat) %*% t(z)
return(H)
}
get_naive_press <- function(X,y,W=NULL,lambda=0,pen.mat = F){
n = length(y)
output.vec = rep(0,n)
X = as.matrix(X)
if(is.null(W)==F){
X = W %*% X
y = W %*% y
}
for(ii in 1:n){
z = X[-ii,] %>% as.matrix()
temp.y = y[-ii] %>% as.matrix()
temp.beta = solve(t(z) %*% z + lambda*pen.mat) %*% t(z) %*% temp.y
pred = t(as.matrix(X[ii,])) %*% temp.beta
output.vec[ii] = (pred - y[ii])^2
}
return((1/n) * sum(output.vec))
}
get_naive_gcv <- function(X,y,W=NULL,lambda=0,pen.mat = diag(1,ncol(X))){
A = get_hat(X,W,lambda,pen.mat)
n = length(y)
output.vec = rep(0,n)
X = as.matrix(X)
if(is.null(W)==F){
X = W %*% X
y = W %*% y
}
for(ii in 1:n){
z = X[-ii,] %>% as.matrix()
temp.y = y[-ii] %>% as.matrix()
temp.beta = solve(t(z) %*% z + lambda*pen.mat) %*% t(z) %*% temp.y
pred = t(as.matrix(X[ii,])) %*% temp.beta
gcv.w_i = (1-A[ii,ii])/(1-(1/n)*tr(A))
output.vec[ii] = (pred - y[ii])^2 * gcv.w_i
}
return((1/n) * sum(output.vec))
}
get_coefs <- function(X,y, lambda,pen.mat, W = NULL){
# If a W is given, COEFS WILL BE FOR THE SMOOTH IN THE TRANSFORMED SPACE
n = nrow(X)
y = as.matrix(y,length(y),1)
if(is.null(W)==F){
X = W %*% X
y = W %*% y
}
output = solve(t(X) %*% X + pen.mat*lambda) %*% t(X) %*% y
return(output)
}
true.coefs <- get_coefs(X, y.true,0,pen.mat)
inprod.mat <- inprod(x.basis, x.basis)
RMSE <- function(coef1,coef2, inprod.mat = inprod.mat){
r.coef = coef1 - coef2
mse = t(r.coef) %*% inprod.mat %*% (r.coef)
return(sqrt(mse[1,1]))
}
test.smooth <- smooth.basis(t.vec, y = y.obs, fdPar(x.basis,lambda = 1))
test.smooth2 <- smooth.basis(t.vec, y = y.obs, fdPar(x.basis,lambda = .99))
all.equal(get_coefs(X,y.obs,1,pen.mat),test.smooth$fd$coefs)
RMSE(test.smooth$fd$coefs,test.smooth2$fd$coefs, inprod.mat)
l.vec <- exp(seq(1,6,.2))
output <- matrix(NA,40,8)
output.objects <- list()
for(ii in 1:nrow(output)){
noise <- rnorm(length(y.true),0,noise.sd)
y.obs <- y.true + noise
# Do a grid search to find the optimal smoothing parameters using the
# different procedures
unweighted.press.vec <- rep(NA,length(l.vec))
unweighted.gcv.vec <- rep(NA,length(l.vec))
weighted.press.vec <- rep(NA,length(l.vec))
weighted.gcv.vec <- rep(NA,length(l.vec))
for(jj in 1:length(l.vec)){
unweighted.press.vec[jj] <- get_naive_press(X = X, y = y.obs,lambda = l.vec[jj],
pen.mat = pen.mat)
unweighted.gcv.vec[jj] <- get_naive_gcv(X = X, y = y.obs,lambda = l.vec[jj],
pen.mat = pen.mat)
weighted.press.vec[jj] <- get_naive_press(X = X, y = y.obs,lambda = l.vec[jj],
pen.mat = pen.mat.W, W = W)
weighted.gcv.vec[jj] <- get_naive_gcv(X = X, y = y.obs,lambda = l.vec[jj],
pen.mat = pen.mat.W, W = W)
}
up.i = which.min(unweighted.press.vec)
ug.i = which.min(unweighted.gcv.vec)
wp.i = which.min(weighted.press.vec)
wg.i = which.min(weighted.gcv.vec)
up.l = l.vec[up.i]
ug.l = l.vec[ug.i]
wp.l = l.vec[wp.i]
wg.l = l.vec[wg.i]
# Coefs give smooth in original space
up.coefs = get_coefs(X,y.obs,up.l,pen.mat)
ug.coefs = get_coefs(X,y.obs,ug.l,pen.mat)
# Coefs give smooth in transformed space
# i.e., W %*% X %*% wp.coefs gives weighted-PRESS-optimal smooth
# in transformed space
wp.coefs = get_coefs(X,y.obs,wp.l,pen.mat.W,W)
wg.coefs = get_coefs(X,y.obs,wg.l,pen.mat.W,W)
# W %*% X %*% wp.coefs gives you the smoothed predictions in transformed space
# To transform back, multiply by W^{-1}
# The predictions back in the original space are
# W^{-1} %*% W %*% X %*% wp.coefs = X %*% wp.coefs
# Because both the weighted and unweighted coefs are multiplied by (the
# original) X, I can use the RMSE function defined above without adjustment.
up.rmse = RMSE(up.coefs,true.coefs,inprod.mat)
ug.rmse = RMSE(ug.coefs,true.coefs,inprod.mat)
wp.rmse = RMSE(wp.coefs,true.coefs,inprod.mat)
wg.rmse = RMSE(wg.coefs,true.coefs,inprod.mat)
output[ii,] = c(up.l,ug.l,wp.l,wg.l,up.rmse,ug.rmse,wp.rmse,wg.rmse)
output.objects[[ii]] = list(noise,y.obs,
unweighted.press.vec,
unweighted.gcv.vec,
weighted.press.vec,
weighted.gcv.vec,
up.coefs,ug.coefs,wp.coefs,wg.coefs)
}
colnames(output) <- c("up.l","ug.l","wp.l","wg.l","up.rmse","ug.rmse","wp.rmse","wg.rmse")
output <- round(output,3) %>% as.data.frame() %>%
mutate(ID=row_number(),.before = 1,
p.improved = (wp.rmse<up.rmse),
g.improved =(wg.rmse<ug.rmse))
output
mean(output$g.improved)
head(pen.mat)
head(pen.mat.W)
post.w <- readRDS("post.w.rds")
post.w <- readRDS("post.w.rds")
getwd()
cd("E:/FunkyStats")
setwd("E:/FunkyStats")
post.w <- readRDS("post.w.rds")
post.w$rowname[1:5]
test=post.w$rowname[1]
test
substr(test,-11,-1)
nchar(test)
substr(test,30,40)
substr(test,31,40)
ids <- as.data.frame(substr(post.w$rowname,31,40))
ids
ids <- data.frame(ID = substr(post.w$rowname,31,40))
ids
ids <- data.frame(ID = substr(post.w$rowname,31,40)) %>% head
has_crop_tools()
Sys.setenv(R_GSCMD="C:/Program Files/gs/gs9.54.0/bin/gswin64.exe")
rmarkdown::metadata("Presentation.Rmd")
rmarkdown::metadata
?rmarkdown::metadata
?rmarkdown::metadata
rmarkdown::metadata
rmarkdown::metadata
---
title: "Assessing Fair Policing in Austin, TX"
author: "Team FunkyStats"
date: "4/18/2021"
abstract: This report demonstrates disparities by race in traffic stops by the Austin Police Department. After exploratory analysis, we assess various models and statistics derived from the hit rate and using the Veil of Darkness. We conclude with a Bayesian hierarchical model that produces officer-level posteriors for the hit rate.
output:
beamer_presentation:
theme: "AnnArbor"
header-includes:
- \usepackage{svg}
- \usepackage{longtable}
- \usepackage{float}
- \floatplacement{figure}{H}
- \usepackage{caption}
bibliography: references.bib
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F,message = F,warning = F,dev = 'pdf',fig.pos = '!H',cache = T)
```
unlink('Presentation_cache', recursive = TRUE)
knitr::opts_chunk$set(echo = F,message = F,warning = F,dev = 'pdf',fig.pos = '!H',cache = T)
rmarkdown::metadata
rmarkdown::metadata
write(rmarkdown::metadata,file = "meta.txt")
post.w <- readRDS("post.w.rds")
post.b <- readRDS("post.b.rds")
post.h <- readRDS("post.h.rds")
A <- post.w %>% head %>% select(2:4) %>% round(3)
B <- post.b %>% head %>% select(2:4) %>% round(3)
C <- post.h %>% head %>% select(2:4) %>% round(3)
rownames(A) = NULL
rownames(B) = NULL
rownames(C) = NULL
ids <- data.frame(ID = substr(post.w$rowname,31,40)) %>% head
ttt <- cbind(ids,A,B,C)
names(ttt) <- c("ID","W 2.5%","W 50%", "W 97.5%","B 2.5%","B 50%", "B 97.5%","H 2.5%","H 50%", "H 97.5%")
ttt %>% kable(caption="Posterior intervals for several officers for three races. From left to right: white, Black, Hispanic") %>%
kable_styling(latex_options = c("striped", "scale_down"))
library(ttidyverse)
library(tidyverse)
post.w <- readRDS("post.w.rds")
post.b <- readRDS("post.b.rds")
post.h <- readRDS("post.h.rds")
A <- post.w %>% head %>% select(2:4) %>% round(3)
B <- post.b %>% head %>% select(2:4) %>% round(3)
C <- post.h %>% head %>% select(2:4) %>% round(3)
rownames(A) = NULL
rownames(B) = NULL
rownames(C) = NULL
ids <- data.frame(ID = substr(post.w$rowname,31,40)) %>% head
ttt <- cbind(ids,A,B,C)
names(ttt) <- c("ID","W 2.5%","W 50%", "W 97.5%","B 2.5%","B 50%", "B 97.5%","H 2.5%","H 50%", "H 97.5%")
ttt %>% kable(caption="Posterior intervals for several officers for three races. From left to right: white, Black, Hispanic") %>%
kable_styling(latex_options = c("striped", "scale_down"))
post.w <- readRDS("post.w.rds")
post.b <- readRDS("post.b.rds")
post.h <- readRDS("post.h.rds")
A <- post.w %>% head %>% select(2:4) %>% round(3)
B <- post.b %>% head %>% select(2:4) %>% round(3)
C <- post.h %>% head %>% select(2:4) %>% round(3)
rownames(A) = NULL
rownames(B) = NULL
rownames(C) = NULL
ids <- data.frame(ID = substr(post.w$rowname,31,40)) %>% head
ttt <- cbind(ids,A,B,C)
names(ttt) <- c("ID","W 2.5%","W 50%", "W 97.5%","B 2.5%","B 50%", "B 97.5%","H 2.5%","H 50%", "H 97.5%")
ttt %>% kable(caption="Posterior intervals for several officers for three races. From left to right: white, Black, Hispanic") %>%
kable_styling(latex_options = c("striped", "scale_down"))
library(kableExtra)
post.w <- readRDS("post.w.rds")
post.b <- readRDS("post.b.rds")
post.h <- readRDS("post.h.rds")
A <- post.w %>% head %>% select(2:4) %>% round(3)
B <- post.b %>% head %>% select(2:4) %>% round(3)
C <- post.h %>% head %>% select(2:4) %>% round(3)
rownames(A) = NULL
rownames(B) = NULL
rownames(C) = NULL
ids <- data.frame(ID = substr(post.w$rowname,31,40)) %>% head
ttt <- cbind(ids,A,B,C)
names(ttt) <- c("ID","W 2.5%","W 50%", "W 97.5%","B 2.5%","B 50%", "B 97.5%","H 2.5%","H 50%", "H 97.5%")
ttt %>% kable(caption="Posterior intervals for several officers for three races. From left to right: white, Black, Hispanic") %>%
kable_styling(latex_options = c("striped", "scale_down"))
library(knitr)
library(kableExtra)
comparisons %>% filter(ID %in% ex5) %>% mutate_if(is.numeric,round,3) %>% kable(caption="Highest 5 scores.", booktabs=T) %>%
kable_styling(latex_options = c("striped", "scale_down"))
post.w <- readRDS("post.w.rds")
post.b <- readRDS("post.b.rds")
post.h <- readRDS("post.h.rds")
A <- post.w %>% head %>% select(2:4) %>% round(3)
B <- post.b %>% head %>% select(2:4) %>% round(3)
C <- post.h %>% head %>% select(2:4) %>% round(3)
rownames(A) = NULL
rownames(B) = NULL
rownames(C) = NULL
ids <- data.frame(ID = substr(post.w$rowname,31,40)) %>% head
ttt <- cbind(ids,A,B,C)
names(ttt) <- c("ID","W 2.5%","W 50%", "W 97.5%","B 2.5%","B 50%", "B 97.5%","H 2.5%","H 50%", "H 97.5%")
ttt %>% kable(caption="Posterior intervals for several officers for three races. From left to right: white, Black, Hispanic", booktabs=T) %>%
kable_styling(latex_options = c("striped", "scale_down"))
comparisons %>% filter(ID %in% ex5) %>% mutate_if(is.numeric,round,3) %>%
kable(caption="Highest 5 scores.", booktabs=T) %>%
kable_styling(latex_options = c("scale_down"))
ttt %>% kable(caption="Posterior intervals for several officers for three races. From left to right: white, Black, Hispanic", booktabs=T) %>%
kable_styling(latex_options = c("scale_down"))
